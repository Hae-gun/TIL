# Hadoop

<hr>

## 하둡 클러스터링 ( multi node 구성 )

* 1개 컴퓨터(vm) : Single node 운영
* 4개 컴퓨터 : multi clustering node

> 설치가 반이다.. 잘 안됨... 많이 복잡함.

* master virtual machine 하나 생성.

  ![image-20200224092118608](2020-02-24_Hadoop.assets/image-20200224092118608.png)

  ![image-20200224092142080](2020-02-24_Hadoop.assets/image-20200224092142080.png)

* Master 메모리는 2GB정도가 처리하는데 속도가 적당.

* 프로세스는 현재 컴퓨터 성능에 따라.

  ![image-20200224092339725](2020-02-24_Hadoop.assets/image-20200224092339725.png)

* setting 에서 .iso image 파일 지정후 리눅스 설치.

* vmnet.sys -> vm network 설정하는 프로그램

  ![image-20200224092958268](2020-02-24_Hadoop.assets/image-20200224092958268.png)

* 저번시간에 지정했던 CentOS 설치시 설정사항 고려하여 설치.

  * 언어설정 : 한국어

  * 키보드설정 : 영어추가

  * 소프트웨어선택 : 개발 및 창조를 위한 워크스테이션

  * 파티션 :  표준 파티션. `swap 2gb`, `/:(root) 나머지용량` 

  * 네트워크 : eno16777736 켬

  * root 암호설정, hadoop 계정생성

    ![image-20200224094308757](2020-02-24_Hadoop.assets/image-20200224094308757.png)

* kdump 비활성.

* root 계정으로 접속.

* 소프트웨어 탭에서 자동 업데이트 해제하기.(책과 버전을 맞추기 위함.)

  ![image-20200224100308892](2020-02-24_Hadoop.assets/image-20200224100308892.png)



* hadoop 은 linux 환경에서 사용가능

## 빅데이터(개념)

* 3V의 특성을 같는다.

  * 규모(Volume) - 데이터의 크기,데이터 생성 주기가 빠르다.

  * 다양성(Variety) - 다양한 종류의 데이터를 수용하는 속성. 각종형태 : 비정형 데이터

    > 정형 데이터 : 타입(길이) primary key

    

  * 속도(velocity) - 저장, 처리 속도가 빠르다.

* 5V 까지 확장. (정확성, 가치)

* 데이터 소스 - 수집 - 저장 - 처리 - 분석 - 표현
  * R은 분석 표현에 특화
  * hadoop은 분석 앞쪽 특화(저장, 처리)
  * 데이터 소스, 수집은 웹서버가 진행.

* master vm에 설치할 것들.
  * ip고정 설정.
  * jdk 설치
  * hadoop설치
  * 복사하여 여러 vm 으로 사용할 예정.

## Linux 환경 설정

<hr>

### yum 업데이트 방지 설정

![image-20200224102221812](2020-02-24_Hadoop.assets/image-20200224102221812.png)

![image-20200224102518543](2020-02-24_Hadoop.assets/image-20200224102518543.png)

* dhcp -> none

* 아래내용추가.

  ![image-20200224102614085](2020-02-24_Hadoop.assets/image-20200224102614085.png)

* network 재시작
* ifconfig로 확인

### yum 자동 업데이트 해제.

![image-20200224102809931](2020-02-24_Hadoop.assets/image-20200224102809931.png)

![image-20200224102853630](2020-02-24_Hadoop.assets/image-20200224102853630.png)

* update block 주석처리

![image-20200224102955866](2020-02-24_Hadoop.assets/image-20200224102955866.png)

![image-20200224103023092](2020-02-24_Hadoop.assets/image-20200224103023092.png)

* updates-source 주석처리

![image-20200224103217127](2020-02-24_Hadoop.assets/image-20200224103217127.png)

* backup 파일 하나 생성.
*  cd /etc/yum.repos.d/  명령어를 사용하여 폴더로 이동.
* 다음 명령어 진행

![image-20200224104854971](2020-02-24_Hadoop.assets/image-20200224104854971.png)

![image-20200224104945967](2020-02-24_Hadoop.assets/image-20200224104945967.png)

![image-20200224105005486](2020-02-24_Hadoop.assets/image-20200224105005486.png)

![image-20200224104833118](2020-02-24_Hadoop.assets/image-20200224104833118.png)

### selinux 사용 방지 설정

![image-20200224105050208](2020-02-24_Hadoop.assets/image-20200224105050208.png)

![image-20200224105157981](2020-02-24_Hadoop.assets/image-20200224105157981.png)

* 수업 편의를 위한 설정.

## Network 설정

<hr>

* 내부적으로 랜덤 포트로 통신이 진행됨. 
* root에서 전체 방화벽 해제.

![image-20200224105416983](2020-02-24_Hadoop.assets/image-20200224105416983.png)

![image-20200224105516997](2020-02-24_Hadoop.assets/image-20200224105516997.png)

* 설정후 네트워크 재시작.



## JDK 설치

<hr>

* hadoop 이 jdk를 이용한 응용프로그램
* openjdk 정보확인.

![image-20200224105630174](2020-02-24_Hadoop.assets/image-20200224105630174.png)

* openjdk 삭제

  ![image-20200224105800827](2020-02-24_Hadoop.assets/image-20200224105800827.png)

* 삭제확인

  ![image-20200224105835367](2020-02-24_Hadoop.assets/image-20200224105835367.png)

  

* root 계정에서 진행.

![image-20200224101906668](2020-02-24_Hadoop.assets/image-20200224101906668.png)

* jdk 압축 이동

  ![image-20200224110043374](2020-02-24_Hadoop.assets/image-20200224110043374.png)

* 압축해제

  ![image-20200224110126952](2020-02-24_Hadoop.assets/image-20200224110126952.png)

* soft link 만들기.(이름 짧게 쓰기위해)

  ![image-20200224110242230](2020-02-24_Hadoop.assets/image-20200224110242230.png)

* PATH 설정(가장 중요함.)

  ![image-20200224110353246](2020-02-24_Hadoop.assets/image-20200224110353246.png)

  ![image-20200224110751931](2020-02-24_Hadoop.assets/image-20200224110751931.png)

  * 리눅스에선 `:` 윈도우에선 `;`

    ![image-20200224110811828](2020-02-24_Hadoop.assets/image-20200224110811828.png)

    * source 명령어로 path 재설정 함.

  * reboot 진행

  * 재실행후 바로 터미널에서 진행

    ![image-20200224110958575](2020-02-24_Hadoop.assets/image-20200224110958575.png)

  * 설치완료.

  * PATH 에 있는 경로들은 path 를 적지 않아도 실행이 가능.





## hadoop 설치

<hr>

### 1. VM 연결 환경설정.

* 하둡을 위한 4개 VM을 서로 연결하는 과정.



* HDFS (Hadoop Distributed File System) : 분산 파일 시스템.
* hadoop 계정에서 진행.
* 하둡 설치 압축파일을 윈도우에서 가져오기.

![image-20200224112655647](2020-02-24_Hadoop.assets/image-20200224112655647.png)

* hadoop 계정 로그아웃.

* host 이름을 바꾸기.

  1. 현재 호스트 이름 확인.

     ![image-20200224113015086](2020-02-24_Hadoop.assets/image-20200224113015086.png)

     * 변경하자..(ip로 식별하면 구분하기 힘드므로 이름을 지정.)

  2. 이름 변경후 확인.

     ![image-20200224113120314](2020-02-24_Hadoop.assets/image-20200224113120314.png)

  3. VMWare종료후 master 파일을 복사후 이름 지정.

     ![image-20200224131318219](2020-02-24_Hadoop.assets/image-20200224131318219.png)

     

  4. VMware에서 openVM 클릭

     ![image-20200224131608678](2020-02-24_Hadoop.assets/image-20200224131608678.png)

  5. 가져온후 이름 변경

     ![image-20200224131642017](2020-02-24_Hadoop.assets/image-20200224131642017.png)

  6. network에서 mac Address확인

     ![image-20200224131805561](2020-02-24_Hadoop.assets/image-20200224131805561.png)

     ![image-20200224131819586](2020-02-24_Hadoop.assets/image-20200224131819586.png)

     * generate로 새로 생성
     * 실행 후 I Moved it으로 실행.

  7. root계정으로 접속한 후 network 설정.

     * 터미널에서 `gedit /etc/sysconfig/network-scripts/ifcfg-eno16777736`에서 ip설정.

     * MAC adress와 ipaddr 변경.

       ![image-20200224132413229](2020-02-24_Hadoop.assets/image-20200224132413229.png)

  8. hostname 을 slave1로 변경.

     ![image-20200224132653744](2020-02-24_Hadoop.assets/image-20200224132653744.png)
  
  9. 네트워크 재시작.
  
     ![image-20200224132732809](2020-02-24_Hadoop.assets/image-20200224132732809.png)
  
  10. 재부팅.
  
  11. 동일하게 2,3도 진행.
  
  
  
  
  
  12. 4대 동시에 켠후.
  
      * master에서![image-20200224135017686](2020-02-24_Hadoop.assets/image-20200224135017686.png)
  
        * 아래와 같이 수정
  
        ![image-20200224135125566](2020-02-24_Hadoop.assets/image-20200224135125566.png)
  
        * 나머지 4개의 컴퓨터에도 동일하게 작성.
  
  13. ping으로 접속확인.
  
      ![image-20200224135711255](2020-02-24_Hadoop.assets/image-20200224135711255.png)
  
  14. 또는 ssh 프로토콜을 이용하여 원격으로 접속.(telnet 방식접속)
  
      ![image-20200224135813438](2020-02-24_Hadoop.assets/image-20200224135813438.png)
  
  15. who를 통해 현재 접속한 계정 정보 알수있음.
  
      ![image-20200224135947539](2020-02-24_Hadoop.assets/image-20200224135947539.png)
  
  16. exit으로 로그아웃
  
      ![image-20200224140111332](2020-02-24_Hadoop.assets/image-20200224140111332.png)
  
  
  
  
  
### 2. ssh key

* ssh key를 이용하여 vm끼리 접속시 암호 없이 접속하기.

   * 마스터의 `hadoop`계정에서 아래 명령어 수행.

     ![image-20200224143331955](2020-02-24_Hadoop.assets/image-20200224143331955.png)

   * 전부 enter로 넘김

     ![image-20200224143408829](2020-02-24_Hadoop.assets/image-20200224143408829.png)

   * ssh-copy-id 로 넘겨주기.

     ![image-20200224143536461](2020-02-24_Hadoop.assets/image-20200224143536461.png)

     * 경로는 위에 생성된 _rsa의 경로.

   * slave1의 hadoop 암호 입력

     ![image-20200224143701693](2020-02-24_Hadoop.assets/image-20200224143701693.png)

   * 암호 없이 접속되는지 확인후 exit(암호없이 접속이 되야 key값을 부여 받은것.)

     ![image-20200224143747939](2020-02-24_Hadoop.assets/image-20200224143747939.png)

   * slave2, 3도 동일하게 진행.
   * 위 수행 결과 4대의 컴퓨터 hadoop 계정끼리 서로 암호없이 접속 가능.

### 3. 하둡설치

   1. 하둡 설치 압축파일 해제.

      ![image-20200224144322411](2020-02-24_Hadoop.assets/image-20200224144322411.png)
   
      압축 해제후...확인
   
      ![image-20200224144356540](2020-02-24_Hadoop.assets/image-20200224144356540.png)
   
   2. slave도 모두 압축 해제.
   
      ![image-20200224144633712](2020-02-24_Hadoop.assets/image-20200224144633712.png)
   
      ![image-20200224144641758](2020-02-24_Hadoop.assets/image-20200224144641758.png)
   
      ![image-20200224144650210](2020-02-24_Hadoop.assets/image-20200224144650210.png)
      
   3. master에서 hadoop/conf 로 이동
   
      ![image-20200224145139734](2020-02-24_Hadoop.assets/image-20200224145139734.png)
      
   4. 수정할 파일들
      
   * 디렉토리 하나 생성.
     
     ![image-20200224151340851](2020-02-24_Hadoop.assets/image-20200224151340851.png)
     
   * 확인
     
     ![image-20200224151412981](2020-02-24_Hadoop.assets/image-20200224151412981.png)
     
   * masters
     
        ![image-20200224145602013](2020-02-24_Hadoop.assets/image-20200224145602013.png)
            
        ![image-20200224145807191](2020-02-24_Hadoop.assets/image-20200224145807191.png)
            
        * 내용 slave1으로 작성. (두번째 master역할을 지정함)
        
      * slvaes
      
        ​	![image-20200224145713524](2020-02-24_Hadoop.assets/image-20200224145713524.png)
      
        * 모두 작성
      
          ![image-20200224145748448](2020-02-24_Hadoop.assets/image-20200224145748448.png)
      
      * hdfs-site.xml
      
        * 열기
      
          ![image-20200224151627877](2020-02-24_Hadoop.assets/image-20200224151627877.png)
      
        * 작성
      
          ![image-20200224151649800](2020-02-24_Hadoop.assets/image-20200224151649800.png)
      
          * dfs : 한개의 파일을 3개의 파일로 나눠서 저장하겠다는 의미.
      
        * 저장 후 닫기.
      
      * core-site.xml
      
        * 열기
      
          ![image-20200224151536791](2020-02-24_Hadoop.assets/image-20200224151536791.png)
      
        * 작성
      
          ![image-20200224151550873](2020-02-24_Hadoop.assets/image-20200224151550873.png)
      
        * 저장 후 닫기.
      
      * mapred-site.xml
      
        * 열기
      
          ![image-20200224151751726](2020-02-24_Hadoop.assets/image-20200224151751726.png)
      
        * 작성
      
          ![image-20200224151801873](2020-02-24_Hadoop.assets/image-20200224151801873.png)
      
        * 저장 후 닫기.
      
      * hadoop-env.sh
      
        ![image-20200224145333879](2020-02-24_Hadoop.assets/image-20200224145333879.png)
      
        ​		![image-20200224145448671](2020-02-24_Hadoop.assets/image-20200224145448671.png)
      
        * 주석 해제후 자바 경로 변경.
        * 저장후 닫기.
      
      * 위 6개 파일을 master에서 진행후 slave에 복사.
      
        * 복사할 파일. `hadoop-env.sh`,`***-site.xml` 총 4개 slaves에 복사.
      
        * 복사하는법
      
          1. scp 명령어 이용 `scp : ssh로 cp를 진행한다는 명령어
      
          2. xml도 복사.
      
             ![image-20200224152745676](2020-02-24_Hadoop.assets/image-20200224152745676.png)
      
          3. 2,3 도 동일하게 진행.
      
        * 하둡 PATH 설정.
        
        * `.bash_profile` 열기
        
          ![image-20200224152951001](2020-02-24_Hadoop.assets/image-20200224152951001.png)
        
        * 아래와 같이 맨아래 3줄 추가.
        
          ![image-20200224153326418](2020-02-24_Hadoop.assets/image-20200224153326418.png)
          
        * source로 설정저장.
        
          ![image-20200224153439450](2020-02-24_Hadoop.assets/image-20200224153439450.png)
        
        * 확인해보기.
        
          ![image-20200224153505286](2020-02-24_Hadoop.assets/image-20200224153505286.png)

### 4. 설치 확인하기

   1. 확인1

      ![image-20200224153754279](2020-02-24_Hadoop.assets/image-20200224153754279.png)

      * 하둡 저장소 초기화 하는 명령어

      ![image-20200224153913803](2020-02-24_Hadoop.assets/image-20200224153913803.png)

      * successfully formatted 나오면 정상.

   2. 확인2

      ![image-20200224154312016](2020-02-24_Hadoop.assets/image-20200224154312016.png)

      * 실행후 `JobTracker` 와 `NameNode` 실행이 되는지 확인.

        ![image-20200224154427201](2020-02-24_Hadoop.assets/image-20200224154427201.png)
      
      * slave1에서 jps로 아래 같이 뜨는지 확인
      
      
      ![image-20200224154529430](2020-02-24_Hadoop.assets/image-20200224154529430.png)
      * slave2, 3는 jps시 아래와 같이 뜨는지 확인.
      
        ![image-20200224160242776](2020-02-24_Hadoop.assets/image-20200224160242776.png)
      
   * 확인후 master에서 중단.
     
     ![image-20200224160416330](2020-02-24_Hadoop.assets/image-20200224160416330.png)
     
   * 종료.
     
        ![image-20200224160506183](2020-02-24_Hadoop.assets/image-20200224160506183.png)

​      

​      

​      

​      

​      

​      

   

